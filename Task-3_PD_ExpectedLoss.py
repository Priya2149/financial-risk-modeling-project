# -*- coding: utf-8 -*-
"""JPMC_Task_3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12rJNq0owMswLhKa93IeIlsQrAy88nxNp
"""

#Probability of Default (PD) and Expected Loss (EL) Model
# ---------------------------------------------------------------
# We train two models:
#   1. Logistic Regression (baseline, industry standard for PD estimation)
#   2. Decision Tree
#
# Both models are evaluated using AUC. In this dataset, results are nearly perfect:
#   - Logistic Regression AUC ≈ 1.00
#   - Decision Tree AUC ≈ 0.996
#
# Logistic Regression performs slightly better, so we use it for Expected Loss calculation.
# The expected_loss() function takes borrower/loan features and exposure as input,
# and returns:
#   - Predicted Probability of Default (PD)
#   - Expected Loss = PD * (1 - Recovery Rate) * Exposure
# With Recovery Rate fixed at 10% (LGD = 90%).

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import roc_auc_score, classification_report

# Load the data

df = pd.read_csv("Task 3 and 4_Loan_Data.csv")

# Assume target column is named "default"
target_col = "default"
X = df.drop(columns=[target_col])
y = df[target_col]

X = pd.get_dummies(X, drop_first=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale numeric features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train Logistic Regression

log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train_scaled, y_train)

y_pred_proba = log_reg.predict_proba(X_test_scaled)[:, 1]
print("LogReg AUC:", roc_auc_score(y_test, y_pred_proba))
print(classification_report(y_test, (y_pred_proba > 0.5).astype(int)))

# Train Decision Tree (for comparison)

tree = DecisionTreeClassifier(max_depth=5, random_state=42)
tree.fit(X_train, y_train)
y_tree_proba = tree.predict_proba(X_test)[:, 1]
print("Decision Tree AUC:", roc_auc_score(y_test, y_tree_proba))

# Expected Loss Function

RECOVERY_RATE = 0.10
LGD = 1 - RECOVERY_RATE

def expected_loss(model, scaler, loan_features: pd.DataFrame, exposure: float) -> float:
    """
    Predict expected loss for a single loan.

    loan_features : pd.DataFrame with same columns as training features
    exposure : loan exposure amount
    """
    lf = pd.get_dummies(loan_features, drop_first=True)
    lf = lf.reindex(columns=X.columns, fill_value=0)  # align with training features
    lf_scaled = scaler.transform(lf)
    pd_prob = model.predict_proba(lf_scaled)[:, 1][0]
    el = pd_prob * LGD * exposure
    return el, pd_prob

# Example test
# For one borrower in the test set with exposure = 100,000:
#   Predicted PD = ~0.00
#   Expected Loss = 0.00
# Other borrowers may give higher PD and non-zero expected losses.

sample = X_test.iloc[[0]]
exposure_amount = 100000
el, pd_prob = expected_loss(log_reg, scaler, sample, exposure_amount)
print(f"Predicted PD: {pd_prob:.2%}, Expected Loss: {el:.2f}")